import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.signal import convolve2d

def load_image_as_dataframe(image_path):
    """
    Load image and convert to pandas DataFrame.
    
    Args:
        image_path (str): Path to the input image
    
    Returns:
        pandas.DataFrame: Image data as DataFrame
    """
    img = Image.open(image_path).convert('L')
    img_array = np.array(img, dtype=np.float32)
    
    # Resize if image is too large for faster processing
    if img_array.shape[0] > 1000 or img_array.shape[1] > 1000:
        from PIL import Image as PILImage
        img_pil = PILImage.fromarray(img_array.astype(np.uint8))
        # Resize to max 800px on longest side
        max_size = 800
        ratio = min(max_size/img_array.shape[0], max_size/img_array.shape[1])
        new_size = (int(img_array.shape[1] * ratio), int(img_array.shape[0] * ratio))
        img_pil = img_pil.resize(new_size, PILImage.Resampling.LANCZOS)
        img_array = np.array(img_pil, dtype=np.float32)
        print(f"Image resized to {img_array.shape} for faster processing")
    
    # Convert to DataFrame with row and column indices
    df = pd.DataFrame(img_array)
    return df

def fast_sobel_edge_detection_pandas(image_path, threshold=50):
    """
    Fast edge detection using Sobel operator with scipy optimization.
    
    Args:
        image_path (str): Path to the input image
        threshold (int): Threshold value for edge detection (0-255)
    
    Returns:
        tuple: (original_df, edges_df, gradient_magnitude_df)
    """
    # Load image as DataFrame
    img_df = load_image_as_dataframe(image_path)
    
    # Define Sobel kernels
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]], dtype=np.float32)
    
    sobel_y = np.array([[-1, -2, -1],
                        [ 0,  0,  0],
                        [ 1,  2,  1]], dtype=np.float32)
    
    # Use scipy's optimized convolution (MUCH faster)
    grad_x = convolve2d(img_df.values, sobel_x, mode='same', boundary='symm')
    grad_y = convolve2d(img_df.values, sobel_y, mode='same', boundary='symm')
    
    # Convert back to DataFrames
    grad_x_df = pd.DataFrame(grad_x, index=img_df.index, columns=img_df.columns)
    grad_y_df = pd.DataFrame(grad_y, index=img_df.index, columns=img_df.columns)
    
    # Calculate gradient magnitude using vectorized operations
    gradient_magnitude_df = pd.DataFrame(
        np.sqrt(grad_x_df.values**2 + grad_y_df.values**2),
        index=img_df.index, 
        columns=img_df.columns
    )
    
    # Apply threshold to create binary edge map
    edges_df = pd.DataFrame(
        (gradient_magnitude_df.values > threshold).astype(int) * 255,
        index=img_df.index,
        columns=img_df.columns
    )
    
    return img_df, edges_df, gradient_magnitude_df

def ultra_fast_sobel_pandas(image_path, threshold=50):
    """
    Ultra-fast edge detection using scipy.ndimage (fastest option).
    
    Args:
        image_path (str): Path to the input image
        threshold (int): Threshold value for edge detection (0-255)
    
    Returns:
        tuple: (original_df, edges_df, gradient_magnitude_df)
    """
    # Load image as DataFrame
    img_df = load_image_as_dataframe(image_path)
    
    # Use scipy's built-in Sobel filters (fastest method)
    grad_x = ndimage.sobel(img_df.values, axis=1)  # Horizontal gradient
    grad_y = ndimage.sobel(img_df.values, axis=0)  # Vertical gradient
    
    # Calculate gradient magnitude
    magnitude = np.sqrt(grad_x**2 + grad_y**2)
    
    # Convert to DataFrames
    grad_x_df = pd.DataFrame(grad_x, index=img_df.index, columns=img_df.columns)
    grad_y_df = pd.DataFrame(grad_y, index=img_df.index, columns=img_df.columns)
    gradient_magnitude_df = pd.DataFrame(magnitude, index=img_df.index, columns=img_df.columns)
    
    # Apply threshold
    edges_df = pd.DataFrame(
        (magnitude > threshold).astype(int) * 255,
        index=img_df.index,
        columns=img_df.columns
    )
    
    return img_df, edges_df, gradient_magnitude_df

def analyze_edges_with_pandas(edges_df, original_df):
    """
    Analyze edge detection results using pandas operations.
    
    Args:
        edges_df (pandas.DataFrame): Edge detection results
        original_df (pandas.DataFrame): Original image data
    
    Returns:
        dict: Analysis results
    """
    # Convert to binary for analysis
    binary_edges = (edges_df > 0).astype(int)
    
    # Calculate statistics using pandas (vectorized operations)
    total_pixels = edges_df.size
    edge_pixels = binary_edges.sum().sum()
    edge_percentage = (edge_pixels / total_pixels) * 100
    
    # Find edge density by region (divide image into quadrants)
    h, w = edges_df.shape
    mid_h, mid_w = h // 2, w // 2
    
    quadrants = {
        'top_left': binary_edges.iloc[:mid_h, :mid_w].sum().sum(),
        'top_right': binary_edges.iloc[:mid_h, mid_w:].sum().sum(),
        'bottom_left': binary_edges.iloc[mid_h:, :mid_w].sum().sum(),
        'bottom_right': binary_edges.iloc[mid_h:, mid_w:].sum().sum()
    }
    
    # Create edge statistics DataFrame
    stats_df = pd.DataFrame({
        'Metric': ['Total Pixels', 'Edge Pixels', 'Edge Percentage', 
                  'Top Left Edges', 'Top Right Edges', 'Bottom Left Edges', 'Bottom Right Edges'],
        'Value': [total_pixels, edge_pixels, f"{edge_percentage:.2f}%",
                 quadrants['top_left'], quadrants['top_right'], 
                 quadrants['bottom_left'], quadrants['bottom_right']]
    })
    
    return {
        'stats': stats_df,
        'quadrants': quadrants,
        'edge_percentage': edge_percentage
    }

def edge_profile_analysis(edges_df):
    """
    Analyze edge profiles using pandas operations.
    
    Args:
        edges_df (pandas.DataFrame): Edge detection results
    
    Returns:
        dict: Profile analysis results
    """
    # Calculate row and column edge profiles (vectorized)
    row_profile = edges_df.sum(axis=1)  # Sum across columns for each row
    col_profile = edges_df.sum(axis=0)  # Sum across rows for each column
    
    # Find rows and columns with most edges
    max_edge_row = row_profile.idxmax()
    max_edge_col = col_profile.idxmax()
    
    # Create profile DataFrames
    row_profile_df = pd.DataFrame({
        'Row': row_profile.index,
        'Edge_Count': row_profile.values
    })
    
    col_profile_df = pd.DataFrame({
        'Column': col_profile.index,
        'Edge_Count': col_profile.values
    })
    
    return {
        'row_profile': row_profile_df,
        'col_profile': col_profile_df,
        'max_edge_row': max_edge_row,
        'max_edge_col': max_edge_col
    }

def visualize_results_with_pandas(original_df, edges_df, analysis_results):
    """
    Visualize edge detection results and analysis.
    
    Args:
        original_df (pandas.DataFrame): Original image
        edges_df (pandas.DataFrame): Edge detection results
        analysis_results (dict): Analysis results
    """
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # Original image
    axes[0, 0].imshow(original_df.values, cmap='gray')
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')
    
    # Detected edges
    axes[0, 1].imshow(edges_df.values, cmap='gray')
    axes[0, 1].set_title('Detected Edges')
    axes[0, 1].axis('off')
    
    # Edge overlay
    overlay = original_df.values.copy()
    edge_mask = edges_df.values > 0
    overlay[edge_mask] = 255
    axes[0, 2].imshow(overlay, cmap='gray')
    axes[0, 2].set_title('Edges Overlay')
    axes[0, 2].axis('off')
    
    # Row profile
    profile_data = analysis_results['profiles']
    axes[1, 0].plot(profile_data['row_profile']['Edge_Count'])
    axes[1, 0].set_title('Row Edge Profile')
    axes[1, 0].set_xlabel('Row Index')
    axes[1, 0].set_ylabel('Edge Count')
    
    # Column profile
    axes[1, 1].plot(profile_data['col_profile']['Edge_Count'])
    axes[1, 1].set_title('Column Edge Profile')
    axes[1, 1].set_xlabel('Column Index')
    axes[1, 1].set_ylabel('Edge Count')
    
    # Statistics text
    stats_text = f"""Edge Statistics:
    Total Pixels: {analysis_results['stats']['Value'][0]}
    Edge Pixels: {analysis_results['stats']['Value'][1]}
    Edge Percentage: {analysis_results['stats']['Value'][2]}
    
    Max Edge Row: {profile_data['max_edge_row']}
    Max Edge Col: {profile_data['max_edge_col']}"""
    
    axes[1, 2].text(0.1, 0.5, stats_text, transform=axes[1, 2].transAxes, 
                   fontsize=10, verticalalignment='center')
    axes[1, 2].set_title('Statistics')
    axes[1, 2].axis('off')
    
    plt.tight_layout()
    plt.show()

def create_edge_dataframe_report(edges_df, original_df):
    """
    Create a comprehensive report of edge detection results using pandas.
    
    Args:
        edges_df (pandas.DataFrame): Edge detection results
        original_df (pandas.DataFrame): Original image data
    
    Returns:
        dict: Comprehensive analysis report
    """
    # Basic statistics
    basic_stats = analyze_edges_with_pandas(edges_df, original_df)
    
    # Profile analysis
    profile_analysis = edge_profile_analysis(edges_df)
    
    # Edge intensity distribution (only for non-zero edges for speed)
    edge_pixels = edges_df.values[edges_df.values > 0]
    if len(edge_pixels) > 0:
        edge_intensity_dist = pd.Series(edge_pixels).describe()
    else:
        edge_intensity_dist = pd.Series([0]).describe()
    
    # Create summary report
    report = {
        'stats': basic_stats['stats'],
        'profiles': profile_analysis,
        'intensity_distribution': edge_intensity_dist,
        'quadrant_analysis': basic_stats['quadrants']
    }
    
    return report

# Example usage with optimized pandas workflow
if __name__ == "__main__":
    import time
    
    try:
        image_path = "pic2_zoomed.png"  # Replace with your image path
        
        print("Starting ULTRA-FAST edge detection...")
        start_time = time.time()
        
        # Use the ultra-fast version
        original_df, edges_df, magnitude_df = ultra_fast_sobel_pandas(image_path, threshold=50)
        
        processing_time = time.time() - start_time
        print(f"Edge detection completed in {processing_time:.3f} seconds")
        
        # Quick analysis
        print("Performing analysis...")
        analysis_start = time.time()
        
        report = create_edge_dataframe_report(edges_df, original_df)
        
        analysis_time = time.time() - analysis_start
        print(f"Analysis completed in {analysis_time:.3f} seconds")
        
        # Display results
        print("\nEdge Detection Analysis Report")
        print("=" * 40)
        print(f"Image size: {original_df.shape}")
        print(f"Processing time: {processing_time:.3f}s")
        print(f"Analysis time: {analysis_time:.3f}s")
        print(f"Total time: {processing_time + analysis_time:.3f}s")
        
        print("\nBasic Statistics:")
        print(report['stats'])
        
        print(f"\nRow with most edges: {report['profiles']['max_edge_row']}")
        print(f"Column with most edges: {report['profiles']['max_edge_col']}")
        
        # Visualize results
        visualize_results_with_pandas(original_df, edges_df, report)
        
        # Save results as CSV files (optional - comment out for speed)
        # edges_df.to_csv('detected_edges.csv')
        # report['profiles']['row_profile'].to_csv('row_edge_profile.csv', index=False)
        # report['profiles']['col_profile'].to_csv('col_edge_profile.csv', index=False)
        
    except FileNotFoundError:
        print("Please provide a valid image path to test the edge detection algorithms.")
        print("Creating synthetic test data...")
        
        # Create synthetic test data as DataFrame (smaller for demo)
        test_data = np.zeros((100, 100))
        test_data[20:80, 20:25] = 255  # Vertical edge
        test_data[40:45, 20:80] = 255  # Horizontal edge
        
        test_df = pd.DataFrame(test_data)
        
        # Apply ultra-fast edge detection
        start_time = time.time()
        
        grad_x = ndimage.sobel(test_df.values, axis=1)
        grad_y = ndimage.sobel(test_df.values, axis=0)
        magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        edges_test_df = pd.DataFrame(
            (magnitude > 50).astype(int) * 255,
            index=test_df.index,
            columns=test_df.columns
        )
        
        processing_time = time.time() - start_time
        print(f"Test processing completed in {processing_time:.4f} seconds")
        
        # Analyze test results
        test_report = create_edge_dataframe_report(edges_test_df, test_df)
        
        print("\nTest Results:")
        print(test_report['stats'])
        
        # Visualize test results
        visualize_results_with_pandas(test_df, edges_test_df, test_report)